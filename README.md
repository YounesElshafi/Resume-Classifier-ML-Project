# ðŸ§  Resume Classifier â€” NLP + Machine Learning Project

Automatically classifies resumes into job categories using NLP techniques and multiple machine learning models.

---

## ðŸ“ Project Structure


 Resume-Classifier-ML-Project/
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ download_data.ipynb
â”‚ â””â”€â”€ resume-dataset/
â”‚ â””â”€â”€ UpdatedResumeDataSet.csv
â”œâ”€â”€ notebook/
â”‚ â”œâ”€â”€ 01_EDA_Resume.ipynb
â”‚ â”œâ”€â”€ 02_Preprocessing_Resume.ipynb
â”‚ â”œâ”€â”€ 03_Model_Training_Evaluation.ipynb
â”‚ â””â”€â”€ 04_Tuning_Model.ipynb
â”œâ”€â”€ models/
â”‚ â”œâ”€â”€ X_train.joblib
â”‚ â”œâ”€â”€ X_test.joblib
â”‚ â”œâ”€â”€ y_train.joblib
â”‚ â””â”€â”€ y_test.joblib
â”œâ”€â”€ images/
â”‚ â”œâ”€â”€ 0.png ... 4.png
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md


---

## ðŸ“Š Dataset

- **Source**: The dataset is downloaded from Kaggle.
- **File**: `UpdatedResumeDataSet.csv`
- **Target Variable**: Category of job role.
- **Text Column**: Resume content.

---

## ðŸ” Project Workflow

### 1. EDA (Exploratory Data Analysis)

- Checked class distribution and common keywords.
- Visualized most frequent words using word clouds and bar charts.

### 2. Preprocessing

- Removed URLs, special characters, stopwords, etc.
- Encoded categorical labels.
- Applied TF-IDF vectorization.
- Split dataset into train and test sets.
- Saved processed data using `joblib`.

### 3. Model Training & Evaluation

Evaluated several classifiers using accuracy, confusion matrix, and classification report:

| Model               | Accuracy |
|---------------------|----------|
| Logistic Regression | 0.53     |
| Random Forest       | 0.76     |
| Naive Bayes         | 0.35     |
| K-Nearest Neighbors | 0.82     |
| One-vs-Rest (SVC)   | 0.79     |
| One-vs-Rest (KNN)   | 0.82     |



## ðŸ”§ Advanced Tuning & Local SVM

In `04_Tuning_Model.ipynb`, we applied two main optimization techniques:

### A. Hyperparameter Tuning with Optuna

- Optimized `C`, `kernel`, and `gamma` parameters for SVC.
- Improved generalization:
  - **Training Accuracy**: dropped slightly (92% â†’ 88%) to reduce overfitting.
  - **Testing Accuracy**: increased (82% â†’ 85%).


> ðŸ” Note: The Optuna optimization code was removed after applying the best


We implemented a **Localized SVM** approach:

- For every resume vector (training or test):
  - Find the `k` nearest neighbors using `sklearn.NearestNeighbors`.
  - Train a dedicated `SVC` model only on those neighbors.
  - Use it to predict the class of the target point.
- If training fails (e.g., only one class), we fallback to the global majority class.

> This method captures **local patterns** in the data and is especially useful in **non-linear or imbalanced** datasets. However, it is computationally expensive, as it trains an SVM for every single point.


---

## ðŸ“ˆ Visualizations

- All plots and evaluation graphs (e.g., word clouds, confusion matrices) are saved in the `images/` folder.


## ðŸ“Œ Future Improvements

- Use advanced NLP models like **BERT**, **spaCy**, or **LlamaIndex**.
- Segment resume content into sections (e.g., skills, education) before classification.
- Build a **Streamlit** or **Flask** app to deploy the model.


## ðŸ“¬ Contact

For any feedback or suggestions, feel free to reach out:

**Name**: Younes Elshafi  
**Email**: [younes.ai.dev@gmail.com](mailto:younes.ai.dev@gmail.com)




